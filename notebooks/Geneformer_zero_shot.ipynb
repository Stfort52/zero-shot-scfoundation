{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64b7280",
   "metadata": {},
   "source": [
    "# Evalutating Geneformer in zero-shot setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be00a33-d204-43b9-8edb-dce6df631946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from sc_foundation_evals import geneformer_forward as gf\n",
    "from sc_foundation_evals import data, cell_embeddings, model_output\n",
    "from sc_foundation_evals.helpers.custom_logging import log\n",
    "\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dddae8",
   "metadata": {},
   "source": [
    "## Setting up variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1178f8e",
   "metadata": {},
   "source": [
    "Define some variables, that we will rely on later, starting with paths and run configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c347ff",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters for papermill\n",
    "model_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/workspace\")\n",
    "geneformer_data = base_dir / \"data/weights/Geneformer\"\n",
    "dict_dir = geneformer_data / \"dicts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9729c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(\"/workspace/models/\") / model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aa0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size depends on available GPU memory\n",
    "batch_size = 24\n",
    "# output_dir is the path to which the results should be saved\n",
    "output_dir = base_dir / \"output/geneformer\" / model_name\n",
    "# path to where we will store the embeddings and other evaluation outputs\n",
    "model_out = output_dir / \"model_outputs\"\n",
    "# if you can use multithreading specify num_workers, -1 means use all available\n",
    "num_workers = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5217358",
   "metadata": {},
   "source": [
    "Data paths and configs.\n",
    "\n",
    "I will be using the Pancreas dataset as an example, as described in the scGPT_zer-shot notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e18c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = base_dir / \"data/datasets\"\n",
    "# specify the path to anndata object\n",
    "in_dataset_path = dataset_dir / \"pancreas_scib.h5ad\"\n",
    "# specify the path for the output of the pre-processing\n",
    "preprocessed_path = dataset_dir / \"geneformer\" / in_dataset_path.stem\n",
    "# create the preprocessed path if it does not exist\n",
    "preprocessed_path.mkdir(parents=True, exist_ok=True)\n",
    "# in which column in adata.obs are gene names stored? if they are in index, the index will be copied to a column with this name\n",
    "gene_col = \"gene_symbols\"\n",
    "# batch column found in adata.obs\n",
    "batch_col = \"batch\"\n",
    "# where are labels stored in adata.obs?\n",
    "label_col = \"celltype\"  # \"str_labels\"\n",
    "# where the raw counts are stored?\n",
    "layer_key = \"counts\"  # \"X\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b836746",
   "metadata": {},
   "source": [
    "## Loading model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ad1f4c-28eb-4d0d-b912-f4674acf94b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneform = gf.Geneformer_instance(\n",
    "    save_dir=output_dir,\n",
    "    saved_model_path=model_dir,\n",
    "    explicit_save_dir=True,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f648ae-f69d-4fed-970e-8dec72d9d634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geneform.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4146fcb5",
   "metadata": {},
   "source": [
    "Load them vocabulary and gene to Ensembl ID matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d6ceb-770b-4317-9439-56e99e4e3735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geneform.load_vocab(dict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = preprocessed_path / in_dataset_path.with_suffix(\".loom\").name\n",
    "dataset_path = preprocessed_path / in_dataset_path.with_suffix(\".dataset\").name\n",
    "\n",
    "if input_file_path.exists():\n",
    "    log.info(\n",
    "        f\"Loading preprocessed input data from {input_file_path} and skipping preprocessing\"\n",
    "    )\n",
    "    input_data = data.InputData(adata_dataset_path=input_file_path)\n",
    "    log.info(f\"Loading complete\")\n",
    "else:\n",
    "    log.info(f\"Preprocessing input data from {in_dataset_path}\")\n",
    "    input_data = data.InputData(adata_dataset_path=in_dataset_path)\n",
    "    input_data.preprocess_data(\n",
    "        gene_col=gene_col,\n",
    "        model_type=\"geneformer\",\n",
    "        save_ext=\"loom\",\n",
    "        gene_name_id_dict=geneform.gene_name_id,\n",
    "        preprocessed_path=preprocessed_path,\n",
    "    )\n",
    "    log.info(f\"Preprocessing complete\")\n",
    "\n",
    "\n",
    "if dataset_path.exists():\n",
    "    log.info(f\"Loading preprocessed dataset from {dataset_path} and skipping tokenization\")\n",
    "    geneform.load_tokenized_dataset(\n",
    "        dataset_path\n",
    "    )\n",
    "    log.info(f\"Loading complete\")\n",
    "else:\n",
    "    log.info(f\"Tokenizing input data\")\n",
    "    geneform.tokenize_data(\n",
    "        adata_path=input_file_path,\n",
    "        dataset_path=dataset_path,\n",
    "        cell_type_col=label_col,\n",
    "    )\n",
    "    log.info(f\"Tokenization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02f5bb",
   "metadata": {},
   "source": [
    "If the data was already tokenized, we can just load it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b531b185",
   "metadata": {},
   "source": [
    "## Evaluating model outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e634f2",
   "metadata": {},
   "source": [
    "First, we will perform forward pass on the model and extract embeddings. We're interested with second to last layer, as per the instructions in the codebase of Geneformer [here](https://huggingface.co/ctheodoris/Geneformer/blob/main/geneformer/emb_extractor.py#L285). Using the argument `layer` we can refer to layers according to python logic (i.e. 0 is the embedding layer, 1 - first layer, 2 is the second layer, etc. and -1 is the last layer, etc.).\n",
    "\n",
    "*Note:* If you get a CUDA out of memory error, you can try reducing the batch size. As a rule of thumb, try batch sizes of multiples of 8, to avoid potential issues with how approximations are handled in CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d662e-02d8-4483-9712-a08c9b3cb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneform.extract_embeddings(data=input_data, batch_size=batch_size, layer=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81654059",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred = model_output.GeneExprPredEval(geneform, output_dir=model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b385dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred.evaluate(n_cells=500, save_rankings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pred.visualize(n_cells=100, cmap=\"mako_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10d4e0",
   "metadata": {},
   "source": [
    "# Evaluate the cell embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b7df94",
   "metadata": {},
   "source": [
    "First, creating cell embeddings evaluation object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6639c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ce = cell_embeddings.CellEmbeddingsEval(\n",
    "    geneform,\n",
    "    data=input_data,\n",
    "    output_dir=model_out,\n",
    "    label_key=label_col,\n",
    "    batch_key=batch_col,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a1f29",
   "metadata": {},
   "source": [
    "Then, evaluating the embeddings. Here, for speed we are subsetting the data to 1000 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f580ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with n_cells you can specify how much to subset the obs for\n",
    "eval_ce.evaluate(n_cells=1000, embedding_key=\"geneformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73907a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with n_cells you can specify how much to subset the obs for\n",
    "eval_ce.evaluate(n_cells=1000, embedding_key=\"geneformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ce.visualize(embedding_key=\"geneformer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
